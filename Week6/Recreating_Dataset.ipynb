{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheth\\Documents\\Masters\\Spring2019\\Data Mining\\Assignments\\Week6\\replicable_dataset.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "input_filename = os.path.join(os.path.expanduser(\"~\"), \"Documents\\Masters\\Spring2019\\Data Mining\\Assignments\\Week6\", \"python_tweets.json\")\n",
    "labels_filename = os.path.join(os.path.expanduser(\"~\"), \"Documents\\Masters\\Spring2019\\Data Mining\\Assignments\\Week6\", \"python_classes.json\")\n",
    "replicable_dataset = os.path.join(os.path.expanduser(\"~\"), \"Documents\\Masters\\Spring2019\\Data Mining\\Assignments\\Week6\", \"replicable_dataset.json\")\n",
    "\n",
    "print(replicable_dataset)\n",
    "\n",
    "import json\n",
    "with open(replicable_dataset) as inf:\n",
    "    tweet_ids = json.load(inf)\n",
    "    \n",
    "#print(tweet_ids)\n",
    "\n",
    "actual_labels = []\n",
    "label_mapping = dict(tweet_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "consumer_key = \"MoBMZzE77TLwpXMTm7Tm37401\"\n",
    "consumer_secret = \"jGPRxos03zyoqz5trR0ynR9RHTffkYXBUljtRSish3P8YDl9er\"\n",
    "access_token = \"2835297398-uHudH16cyj5lkDTrWJMOYUhTulYwc77nUZQn2Sv\"\n",
    "access_token_secret = \"eJINvSKJeHAdjnNFJl1PJVI2J9r7EVYrowVX4lsgCd2Aj\"\n",
    "authorization = twitter.OAuth(access_token, access_token_secret, consumer_key, consumer_secret)\n",
    "t = twitter.Twitter(auth=authorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104408732824469504\n",
      "1104409672000434176\n",
      "1104410028889522177\n",
      "1104409642174763009\n",
      "1104409803030441984\n",
      "1104409698789441539\n",
      "1104409518858006528\n",
      "1104408808175079429\n",
      "1104409173956136960\n",
      "1104408883882348544\n",
      "1104409686626000896\n",
      "1104409410338729984\n",
      "1104409449308057600\n",
      "1104409198291501056\n",
      "1104410376849031170\n",
      "1104409558070513664\n",
      "1104409479758655490\n",
      "1104409664928866304\n",
      "1104409043207184385\n",
      "1104409923939635201\n",
      "1104409585769738240\n",
      "1104409009514340353\n",
      "1104410231696572416\n",
      "1104410337141575680\n",
      "1104410028944035846\n",
      "1104409055857074176\n",
      "1104409678325403648\n",
      "1104409954574721025\n",
      "1104408669234651142\n",
      "1104409376188698629\n",
      "1104410413511397377\n",
      "1104409742003310592\n",
      "1104409101080186880\n",
      "1104409613489840128\n",
      "1104408708455505926\n",
      "1104409254897876992\n",
      "1104409745711079424\n",
      "1104410464455286784\n",
      "1104409702652354563\n",
      "1104410091585847296\n",
      "1104409577309782016\n",
      "1104408813946445825\n",
      "1104410234334990336\n",
      "1104409808671662080\n",
      "1104408907772919808\n",
      "1104409254885236739\n",
      "1104410357056053254\n",
      "1104409074374987776\n",
      "1104410391478763526\n",
      "1104410462484086784\n",
      "1104409389975236614\n",
      "1104408684719939585\n",
      "1104408895231946752\n"
     ]
    }
   ],
   "source": [
    "all_ids = [tweet_id for tweet_id, label in tweet_ids]\n",
    "\n",
    "with open(input_filename , 'a') as output_file:\n",
    "    # We can lookup 100 tweets at a time, which saves time in asking twitter for them\n",
    "    for start_index in range(0, len(all_ids), 100):\n",
    "        id_string = \",\".join(str(i) for i in all_ids[start_index:start_index+100])\n",
    "        search_results = t.statuses.lookup(_id=id_string)\n",
    "        for tweet in search_results:\n",
    "            if 'text' in tweet:\n",
    "                # Valid tweet - save to file\n",
    "                output_file.write(json.dumps(tweet))\n",
    "                output_file.write(\"\\n\\n\")\n",
    "                actual_labels.append(label_mapping[tweet['id']])\n",
    "                print(tweet['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(labels_filename, 'w') as outf:\n",
    "    json.dump(actual_labels, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 53)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_labels), len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
